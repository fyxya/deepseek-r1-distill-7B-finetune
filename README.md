# DeepSeek-R1-Distill-7B-SFT-Project

æœ¬é¡¹ç›®åŸºäºDeepSeek-R1-Distill-Qwen-7Bæ¨¡å‹è¿›è¡Œè§’è‰²æ‰®æ¼”å¾®è°ƒï¼Œå®ç°ä¸ã€ŠFate/stay nightã€‹ä¸­Saberï¼ˆé˜¿å°”æ‰˜è‰é›…ï¼‰çš„è§’è‰²å¯¹è¯åŠŸèƒ½ã€‚

## âœ¨ åŠŸèƒ½ç‰¹æ€§
- **é«˜æ•ˆå¾®è°ƒ**ï¼šä½¿ç”¨LoRA+4ä½é‡åŒ–æŠ€æœ¯ï¼Œæ¶ˆè´¹çº§æ˜¾å¡å¯è®­ç»ƒ
- **è§’è‰²è¿˜åŸ**ï¼šå®šåˆ¶åŒ–å¯¹è¯æ•°æ®é›†ï¼Œé«˜åº¦è¿˜åŸSaberè¯­è¨€é£æ ¼
- **ç”Ÿäº§éƒ¨ç½²**ï¼šæ”¯æŒå…¨é‡æ¨¡å‹å¯¼å‡ºä¸4ä½é‡åŒ–æ¨ç†
- **å¯¹è¯æ¨¡æ¿**ï¼šPrompt: {ç”¨æˆ·è¾“å…¥} Completion: {è§’è‰²å›ç­”}<|endoftext|>

- ## ğŸ“¦ ç¯å¢ƒä¾èµ–
- pip install -r requirements.txt

## ğŸš€ å¿«é€Ÿå¼€å§‹
- è®­ç»ƒ
- python main.py
- æ¨ç†
- python inference.py

## ğŸ“‚ æ•°æ®é›†ç»“æ„
json {"prompt": "ç”¨æˆ·è¾“å…¥", "completion": "è§’è‰²å›ç­”"}

## âš™ï¸ è®­ç»ƒé…ç½®
LoRAé…ç½®
LoraConfig( r=4, lora_alpha=8, lora_dropout=0.1, task_type=TaskType.CAUSAL_LM )
è®­ç»ƒå‚æ•°
TrainingArguments( num_train_epochs=10, per_device_train_batch_size=1, gradient_accumulation_steps=4, learning_rate=5e-5, fp16=True, optim="adamw_bnb_8bit" )

## ğŸ’¾ æ¨¡å‹ä¿å­˜
ä¿å­˜LoRAé€‚é…å™¨
model.save_pretrained("./saved_lora_models")
åˆå¹¶å¹¶ä¿å­˜å…¨é‡æ¨¡å‹
merged_model = model.merge_and_unload() merged_model.save_pretrained("./final_saved_models")


